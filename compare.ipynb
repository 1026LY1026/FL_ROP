{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d2b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "model_pre_len = 100\n",
    "model_seq_len = 300\n",
    "model_tf_lr = 0.0001\n",
    "model_batch = 64\n",
    "model_feature_size=5\n",
    "model_d_model=256\n",
    "model_num_layers=1\n",
    "model_dropout=0.1\n",
    "\n",
    "# USE_MULTI_GPU = True\n",
    "# # 设置默认的CUDA设备\n",
    "# torch.cuda.set_device(0)\n",
    "# # 初始化CUDA环境\n",
    "# torch.cuda.init()\n",
    "# if USE_MULTI_GPU and torch.cuda.device_count() > 1:\n",
    "#     MULTI_GPU = True\n",
    "#     os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5\"  # 设置所有六张显卡的编号\n",
    "#     device_ids = ['0','1','2','3','4','5',] # 设置所有六张显卡的编号\n",
    "# else:\n",
    "#     MULTI_GPU = False\n",
    "#     device_ids = ['0']\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(MULTI_GPU)\n",
    "# deviceCount = torch.cuda.device_count()\n",
    "# torch.cuda.set_device(device)\n",
    "# print(deviceCount)\n",
    "# print(device)\n",
    "\n",
    "volve_4 = './data/volve/volve_4.csv'\n",
    "volve_5 = './data/volve/volve_5.csv'\n",
    "volve_7 = './data/volve/volve_7.csv'\n",
    "volve_9 = './data/volve/volve_9.csv'\n",
    "volve_9A = './data/volve/volve_9A.csv'\n",
    "volve_10 = './data/volve/volve_10.csv'\n",
    "volve_12 = './data/volve/volve_12.csv'\n",
    "volve_14 = './data/volve/volve_14.csv'\n",
    "volve_15A = './data/volve/volve_15A.csv'\n",
    "volve_4_5_7_9A_10 = './data/volve/volve_4_5_7_9A_10.csv'\n",
    "volve_5_7_10_12 = './data/volve/volve_5_7_10_12.csv'\n",
    "xj_3 =  './data/xj/well_3.csv'\n",
    "xj_2 = './data/xj/well_2.csv'\n",
    "xj_1 = './data/xj/well_1.csv'\n",
    "\n",
    "bh_1 = './data/bh/bh_1.csv'\n",
    "bh_2 = './data/bh/bh_2.csv'\n",
    "bh_3 = './data/bh/bh_3.csv'\n",
    "bh_4 = './data/bh/bh_4.csv'\n",
    "bh_5 = './data/bh/bh_5.csv'\n",
    "bh_6 = './data/bh/bh_6.csv'\n",
    "bh_7 = './data/bh/bh_7.csv'\n",
    "bh_8 = './data/bh/bh_8.csv'\n",
    "bh_9 = './data/bh/bh_9.csv'\n",
    "bh_10 = './data/bh/bh_10.csv'\n",
    "bh_11 = './data/bh/bh_11.csv'\n",
    "bh_12 = './data/bh/bh_12.csv'\n",
    "bh_14 = './data/bh/bh_14.csv'\n",
    "bh_15 = './data/bh/bh_15.csv'\n",
    "bh_16 = './data/bh/bh_16csv'\n",
    "bh_7_15 = './data/bh/bh_7_15.csv'\n",
    "# 创建一个字典，其中包含所有客户端的训练和测试指标列表\n",
    "loss_acc_r2_mse_mae_metrics = {\n",
    "    'client_0': {\n",
    "        'train': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        },\n",
    "        'test': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        }\n",
    "    },\n",
    "    'client_1': {\n",
    "        'train': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        },\n",
    "        'test': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        }\n",
    "    },\n",
    "    'client_2': {\n",
    "        'train': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        },\n",
    "        'test': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        }\n",
    "    },\n",
    "    'server_model': {\n",
    "        'test_volve': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        },\n",
    "        'test_xj': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        },\n",
    "        'test_bh': {\n",
    "            'acc_size': [],'r2_size': [],'mse_size': [],'mae_size': [],'loss_size': []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "de_t_p_metrics = {\n",
    "    'client_0': {\n",
    "        'train': {'depth': [],'true': [],'pre': []},\n",
    "        'test': {'depth': [],'r2_size': [],'true': [],'pre': []}\n",
    "    },\n",
    "    'client_1': {\n",
    "        'train': {'depth': [], 'true': [], 'pre': []},\n",
    "        'test': {'depth': [], 'true': [], 'pre': []}\n",
    "    },\n",
    "    'client_2': {\n",
    "        'train': {'depth': [], 'true': [], 'pre': []},\n",
    "        'test': {'depth': [], 'true': [], 'pre': []}\n",
    "    },\n",
    "    'server_model': {\n",
    "        'test_volve': {'depth': [], 'true': [], 'pre': []},\n",
    "        'test_xj': {'depth': [], 'true': [], 'pre': []},\n",
    "        'test_bh': {'depth': [], 'true': [], 'pre': []},\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4b4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pylab import mpl\n",
    "from utility_compare import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置matplotlib的配置\n",
    "# mpl.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体为黑体\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # 64*512\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # 64*1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # 256   model/2\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)  # 64*1*512\n",
    "\n",
    "    def forward(self, x):  # [seq,batch,d_model]\n",
    "        return x + self.pe[:x.size(0), :]  # 64*64*512\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=model_feature_size, d_model=model_d_model, num_layers=model_num_layers, dropout=model_dropout):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embedding = nn.Linear(feature_size, d_model)\n",
    "        self.dec_input_fc = nn.Linear(feature_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)  # 50*512\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=8, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=8, dropout=dropout, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "        self.src_mask = None\n",
    "        self.src_key_padding_mask = None\n",
    "\n",
    "    def forward(self, src,tgt,tgt_mask):\n",
    "\n",
    "        # if self.src_key_padding_mask is None:\n",
    "        #     mask_key = src_padding  # [batch,seq]\n",
    "        #     self.src_key_padding_mask = mask_key\n",
    "        src_em = self.embedding(src)  # [seq,batch,d_model]\n",
    "        src_em_pos = self.pos_encoder(src_em)  # [seq,batch,d_model]\n",
    "        encoder_output = self.transformer_encoder(src_em_pos)\n",
    "\n",
    "        tgt_em = self.embedding(tgt)\n",
    "        tgt_em_pos = self.pos_encoder(tgt_em)\n",
    "\n",
    "        decoder_output = self.transformer_decoder(tgt_em_pos, encoder_output, tgt_mask=tgt_mask)\n",
    "\n",
    "        output = self.linear(decoder_output)\n",
    "        output_squeeze = output.squeeze()\n",
    "\n",
    "        self.tgt_mask = None\n",
    "        return output_squeeze\n",
    "\n",
    "\n",
    "def data_load(path):\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    # data = data[['MD', 'TVD', 'RPMA', 'WOBA', 'ROPA']]\n",
    "   # data = data.iloc[::interval, :]\n",
    "\n",
    "    # data = data.clip(lower=0)  # 设置小于0的数都赋0\n",
    "    # data = data.apply(lambda x: x.mask((x < x.quantile(0.25) - 1.5 * (x.quantile(0.75) - x.quantile(0.25))) |\n",
    "    #                                      (x > x.quantile(0.75) + 1.5 * (\n",
    "    #                                                  x.quantile(0.75) - x.quantile(0.25)))).ffill().bfill())\n",
    "    #\n",
    "    # data = data.sort_values(by='MD')\n",
    "    # data=data.reset_index(drop=True)\n",
    "    data = data.astype('float32')\n",
    "    data.dropna(inplace=True)\n",
    "    data = data.values\n",
    "\n",
    "    data_ =torch.tensor(data[:len(data)])\n",
    "    maxc, _ = data_.max(dim=0)\n",
    "    minc, _ = data_.min(dim=0)\n",
    "    y_max = maxc[-1]\n",
    "    y_min = minc[-1]\n",
    "    de_max = maxc[0]\n",
    "    de_min = minc[0]\n",
    "    data_ = (data_ - minc) / (maxc - minc)\n",
    "\n",
    "    data_last_index = data_.shape[0] - model_seq_len\n",
    "\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for i in range(0, data_last_index - model_pre_len+1):\n",
    "        data_x = np.expand_dims(data_[i:i + model_seq_len], 0)  # [1,seq,feature_size]\n",
    "        data_y = np.expand_dims(data_[i + model_seq_len:i + model_seq_len + model_pre_len], 0)  # [1,seq,out_size]\n",
    "        data_X.append(data_x)\n",
    "        data_Y.append(data_y)\n",
    "\n",
    "    data_X=np.concatenate(data_X, axis=0)\n",
    "    data_Y = np.concatenate(data_Y, axis=0)\n",
    "\n",
    "    process_data = torch.from_numpy(data_X).type(torch.float32)\n",
    "    process_label = torch.from_numpy(data_Y).type(torch.float32)\n",
    "\n",
    "    data_feature_size = process_data.shape[-1]\n",
    "\n",
    "    dataset_train = TensorDataset(process_data, process_label)\n",
    "\n",
    "    data_dataloader = DataLoader(dataset_train, batch_size=model_batch, shuffle=False)\n",
    "    return data_dataloader,y_max,y_min, de_max,de_min\n",
    "\n",
    "def averages(matrix):  # 计算平均值\n",
    "    matrix = np.array(matrix)\n",
    "    row_count, col_count = matrix.shape\n",
    "    max_diagonal = row_count + col_count - 1\n",
    "    diagonals = np.zeros(max_diagonal)\n",
    "    counts = np.zeros(max_diagonal, dtype=int)\n",
    "    for i in range(row_count):\n",
    "        for j in range(col_count):\n",
    "            num = matrix[i, j]\n",
    "            diagonal_index = i + j\n",
    "            diagonals[diagonal_index] += num\n",
    "            counts[diagonal_index] += 1\n",
    "    averages = diagonals / counts\n",
    "    return averages\n",
    "\n",
    "def acc_loss_plot_one(train_data, type_, path):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data, label='train_data', color='blue', linewidth=1)\n",
    "    plt.xlabel('epoch', fontsize=18)\n",
    "    plt.title(f'train_test_{type_}')\n",
    "    path_ = f'{path}'\n",
    "\n",
    "    plt.grid()\n",
    "    plt.savefig(path_)\n",
    "\n",
    "    plt.legend()\n",
    "   # plt.show()\n",
    "\n",
    "def acc_loss_plot_two(train_data, test_data, type_, path):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data, label='train_data', color='blue', linewidth=1)\n",
    "    plt.plot(test_data, label='test_data', color='red', linewidth=1)\n",
    "    plt.xlabel('epoch', fontsize=18)\n",
    "    plt.title(f'train_test_{type_}')\n",
    "    path_ = f'{path}'\n",
    "\n",
    "    plt.grid()\n",
    "    plt.savefig(path_)\n",
    "\n",
    "    plt.legend()\n",
    "  #  plt.show()\n",
    "\n",
    "def true_test_plot(depth, true_data, predicted_data, type_, path):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.plot(depth, true_data, label='true_data', color='blue', linewidth=1)\n",
    "    plt.plot(depth, predicted_data, label='test_data', color='green', linewidth=1)\n",
    "    plt.ylabel(\"GRA\", fontsize=18)\n",
    "    plt.xlabel('depth', fontsize=18)\n",
    "    path_ = f'{path}'\n",
    "    plt.grid()\n",
    "    plt.savefig(path_)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7228eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "1\n",
      "cuda:0\n",
      "Epoch: train 0000 loss = 27.933239  acc = 0.197876  r2 = -0.436275  mse = 84.922292  mae = 8.175885 time =  2025-02-18 09:22:28.538324\n",
      "Epoch: test 0000 loss = 7.599883  acc = 0.370613  r2 = -1.324057  mse = 29.795908  mae = 5.046198 time =  2025-02-18 09:22:28.538324\n",
      "Epoch: train 0001 loss = 30.732374  acc = 0.420232  r2 = -0.585276  mse = 93.732199  mae = 7.946077 time =  2025-02-18 09:25:17.147501\n",
      "Epoch: test 0001 loss = 8.340499  acc = 0.413842  r2 = -1.553466  mse = 32.737077  mae = 5.067267 time =  2025-02-18 09:25:17.147501\n",
      "Epoch: train 0002 loss = 14.411885  acc = 0.432292  r2 = 0.259086  mse = 43.807841  mae = 5.840120 time =  2025-02-18 09:28:06.023568\n",
      "Epoch: test 0002 loss = 3.933378  acc = 0.559199  r2 = -0.202270  mse = 15.413877  mae = 3.594699 time =  2025-02-18 09:28:06.023568\n",
      "Epoch: train 0003 loss = 0.107105  acc = 0.967462  r2 = 0.994940  mse = 0.299157  mae = 0.431964 time =  2025-02-18 09:30:54.771781\n",
      "Epoch: test 0003 loss = 0.021775  acc = 0.971075  r2 = 0.994080  mse = 0.075900  mae = 0.239741 time =  2025-02-18 09:30:54.771781\n",
      "Epoch: train 0004 loss = 0.405404  acc = 0.916075  r2 = 0.979881  mse = 1.189575  mae = 0.952893 time =  2025-02-18 09:33:43.302817\n",
      "Epoch: test 0004 loss = 0.066405  acc = 0.935117  r2 = 0.980949  mse = 0.244252  mae = 0.467995 time =  2025-02-18 09:33:43.302817\n",
      "Epoch: train 0005 loss = 0.515052  acc = 0.892880  r2 = 0.973819  mse = 1.548024  mae = 1.119363 time =  2025-02-18 09:36:31.771627\n",
      "Epoch: test 0005 loss = 0.073623  acc = 0.928303  r2 = 0.977903  mse = 0.283298  mae = 0.500957 time =  2025-02-18 09:36:31.771627\n",
      "Epoch: train 0006 loss = 0.770151  acc = 0.853887  r2 = 0.960786  mse = 2.318585  mae = 1.399670 time =  2025-02-18 09:39:20.505352\n",
      "Epoch: test 0006 loss = 0.108090  acc = 0.908995  r2 = 0.967276  mse = 0.419549  mae = 0.591467 time =  2025-02-18 09:39:20.505352\n",
      "Epoch: train 0007 loss = 1.972536  acc = 0.804028  r2 = 0.898572  mse = 5.997134  mae = 2.191635 time =  2025-02-18 09:42:09.122944\n",
      "Epoch: test 0007 loss = 0.362412  acc = 0.851379  r2 = 0.888621  mse = 1.427952  mae = 1.128894 time =  2025-02-18 09:42:09.122944\n",
      "Epoch: train 0008 loss = 0.854933  acc = 0.843528  r2 = 0.956360  mse = 2.580288  mae = 1.468466 time =  2025-02-18 09:44:58.084751\n",
      "Epoch: test 0008 loss = 0.116851  acc = 0.904706  r2 = 0.964316  mse = 0.457485  mae = 0.597111 time =  2025-02-18 09:44:58.084751\n",
      "Epoch: train 0009 loss = 1.001839  acc = 0.828005  r2 = 0.948793  mse = 3.027674  mae = 1.598123 time =  2025-02-18 09:47:46.558538\n",
      "Epoch: test 0009 loss = 0.137108  acc = 0.897034  r2 = 0.958104  mse = 0.537137  mae = 0.648843 time =  2025-02-18 09:47:46.558538\n",
      "Epoch: train 0010 loss = 1.516218  acc = 0.783927  r2 = 0.922267  mse = 4.596103  mae = 1.986688 time =  2025-02-18 09:50:35.167442\n",
      "Epoch: test 0010 loss = 0.216852  acc = 0.869842  r2 = 0.933476  mse = 0.852877  mae = 0.840825 time =  2025-02-18 09:50:35.167442\n",
      "Epoch: train 0011 loss = 1.563062  acc = 0.782249  r2 = 0.920211  mse = 4.717639  mae = 2.013379 time =  2025-02-18 09:53:24.203326\n",
      "Epoch: test 0011 loss = 0.222666  acc = 0.870274  r2 = 0.932220  mse = 0.868982  mae = 0.843681 time =  2025-02-18 09:53:24.203326\n",
      "Epoch: train 0012 loss = 1.241798  acc = 0.815869  r2 = 0.936748  mse = 3.739910  mae = 1.767825 time =  2025-02-18 09:56:12.791688\n",
      "Epoch: test 0012 loss = 0.168866  acc = 0.889122  r2 = 0.948828  mse = 0.656053  mae = 0.714841 time =  2025-02-18 09:56:12.791688\n",
      "Epoch: train 0013 loss = 0.520878  acc = 0.879080  r2 = 0.974079  mse = 1.532632  mae = 1.075597 time =  2025-02-18 09:59:01.813612\n",
      "Epoch: test 0013 loss = 0.066620  acc = 0.940625  r2 = 0.980858  mse = 0.245408  mae = 0.417165 time =  2025-02-18 09:59:01.813612\n",
      "Epoch: train 0014 loss = 2.237556  acc = 0.754471  r2 = 0.885062  mse = 6.795932  mae = 2.401294 time =  2025-02-18 10:01:50.268648\n",
      "Epoch: test 0014 loss = 0.357881  acc = 0.836958  r2 = 0.889862  mse = 1.412035  mae = 1.115355 time =  2025-02-18 10:01:50.268648\n",
      "Epoch: train 0015 loss = 0.793585  acc = 0.848103  r2 = 0.959487  mse = 2.395421  mae = 1.420376 time =  2025-02-18 10:04:38.863065\n",
      "Epoch: test 0015 loss = 0.115702  acc = 0.904553  r2 = 0.964711  mse = 0.452427  mae = 0.598281 time =  2025-02-18 10:04:38.863065\n",
      "Epoch: train 0016 loss = 0.986228  acc = 0.845778  r2 = 0.949695  mse = 2.974399  mae = 1.555859 time =  2025-02-18 10:07:31.063435\n",
      "Epoch: test 0016 loss = 0.139858  acc = 0.900108  r2 = 0.957537  mse = 0.544406  mae = 0.650088 time =  2025-02-18 10:07:31.063435\n",
      "Epoch: train 0017 loss = 1.075223  acc = 0.829509  r2 = 0.945166  mse = 3.242171  mae = 1.638652 time =  2025-02-18 10:10:20.133903\n",
      "Epoch: test 0017 loss = 0.151912  acc = 0.893245  r2 = 0.953912  mse = 0.590877  mae = 0.680575 time =  2025-02-18 10:10:20.133903\n",
      "Epoch: train 0018 loss = 1.420914  acc = 0.814206  r2 = 0.927419  mse = 4.291489  mae = 1.879279 time =  2025-02-18 10:13:08.688493\n",
      "Epoch: test 0018 loss = 0.206416  acc = 0.879371  r2 = 0.937184  mse = 0.805336  mae = 0.792772 time =  2025-02-18 10:13:08.688493\n",
      "Epoch: train 0019 loss = 1.599449  acc = 0.817720  r2 = 0.918471  mse = 4.820562  mae = 1.943304 time =  2025-02-18 10:15:57.510668\n",
      "Epoch: test 0019 loss = 0.237494  acc = 0.881243  r2 = 0.928106  mse = 0.921728  mae = 0.860769 time =  2025-02-18 10:15:57.510668\n",
      "Epoch: train 0020 loss = 1.274984  acc = 0.819994  r2 = 0.935367  mse = 3.821516  mae = 1.768361 time =  2025-02-18 10:18:46.228378\n",
      "Epoch: test 0020 loss = 0.181420  acc = 0.887229  r2 = 0.945607  mse = 0.697348  mae = 0.733492 time =  2025-02-18 10:18:46.228378\n",
      "Epoch: train 0021 loss = 1.428314  acc = 0.784788  r2 = 0.927121  mse = 4.309107  mae = 1.930292 time =  2025-02-18 10:21:34.735678\n",
      "Epoch: test 0021 loss = 0.217232  acc = 0.870218  r2 = 0.933963  mse = 0.846643  mae = 0.825994 time =  2025-02-18 10:21:34.735678\n",
      "Epoch: train 0022 loss = 0.880242  acc = 0.858969  r2 = 0.959308  mse = 2.405998  mae = 1.333360 time =  2025-02-18 10:24:23.698516\n",
      "Epoch: test 0022 loss = 0.123464  acc = 0.926725  r2 = 0.967828  mse = 0.412466  mae = 0.533444 time =  2025-02-18 10:24:23.698516\n",
      "Epoch: train 0023 loss = 1.143338  acc = 0.832816  r2 = 0.941734  mse = 3.445105  mae = 1.689525 time =  2025-02-18 10:27:12.252704\n",
      "Epoch: test 0023 loss = 0.173098  acc = 0.887069  r2 = 0.947593  mse = 0.671888  mae = 0.734824 time =  2025-02-18 10:27:12.252704\n",
      "Epoch: train 0024 loss = 0.776440  acc = 0.860381  r2 = 0.960915  mse = 2.310983  mae = 1.372814 time =  2025-02-18 10:30:00.386094\n",
      "Epoch: test 0024 loss = 0.112891  acc = 0.910081  r2 = 0.966775  mse = 0.425970  mae = 0.580021 time =  2025-02-18 10:30:00.386094\n",
      "Epoch: train 0025 loss = 12.833789  acc = 0.527812  r2 = 0.339498  mse = 39.053329  mae = 5.511336 time =  2025-02-18 10:32:48.740979\n",
      "Epoch: test 0025 loss = 3.064027  acc = 0.588921  r2 = 0.060431  mse = 12.045878  mae = 3.257224 time =  2025-02-18 10:32:48.740979\n",
      "Epoch: train 0026 loss = 0.536182  acc = 0.877162  r2 = 0.973486  mse = 1.567682  mae = 1.135467 time =  2025-02-18 10:35:36.984489\n",
      "Epoch: test 0026 loss = 0.089956  acc = 0.913826  r2 = 0.974136  mse = 0.331599  mae = 0.516057 time =  2025-02-18 10:35:36.984489\n",
      "Epoch: train 0027 loss = 0.804914  acc = 0.861499  r2 = 0.959441  mse = 2.398111  mae = 1.413061 time =  2025-02-18 10:38:25.198653\n",
      "Epoch: test 0027 loss = 0.125128  acc = 0.903750  r2 = 0.962904  mse = 0.475590  mae = 0.626735 time =  2025-02-18 10:38:25.198653\n",
      "Epoch: train 0028 loss = 0.604247  acc = 0.877984  r2 = 0.969966  mse = 1.775828  mae = 1.191417 time =  2025-02-18 10:41:13.421420\n",
      "Epoch: test 0028 loss = 0.087016  acc = 0.922666  r2 = 0.975141  mse = 0.318715  mae = 0.501224 time =  2025-02-18 10:41:13.421420\n",
      "Epoch: train 0029 loss = 0.855553  acc = 0.855662  r2 = 0.957114  mse = 2.535694  mae = 1.434253 time =  2025-02-18 10:44:01.972734\n",
      "Epoch: test 0029 loss = 0.121631  acc = 0.906775  r2 = 0.964665  mse = 0.453023  mae = 0.600238 time =  2025-02-18 10:44:01.972734\n",
      "Epoch: train 0030 loss = 1.244045  acc = 0.831686  r2 = 0.937074  mse = 3.720610  mae = 1.738903 time =  2025-02-18 10:46:50.544387\n",
      "Epoch: test 0030 loss = 0.185317  acc = 0.887418  r2 = 0.944884  mse = 0.706622  mae = 0.744847 time =  2025-02-18 10:46:50.544387\n",
      "Epoch: train 0031 loss = 0.592740  acc = 0.877185  r2 = 0.970392  mse = 1.750644  mae = 1.141367 time =  2025-02-18 10:49:39.297688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: test 0031 loss = 0.078507  acc = 0.937659  r2 = 0.977406  mse = 0.289668  mae = 0.450740 time =  2025-02-18 10:49:39.297688\n",
      "Epoch: train 0032 loss = 1.226216  acc = 0.795639  r2 = 0.937680  mse = 3.684753  mae = 1.782634 time =  2025-02-18 10:52:27.682100\n",
      "Epoch: test 0032 loss = 0.184641  acc = 0.876835  r2 = 0.944373  mse = 0.713168  mae = 0.759069 time =  2025-02-18 10:52:27.682100\n",
      "Epoch: train 0033 loss = 16.007880  acc = 0.298313  r2 = 0.178257  mse = 48.586970  mae = 6.468419 time =  2025-02-18 10:55:16.081049\n",
      "Epoch: test 0033 loss = 3.695884  acc = 0.503652  r2 = -0.132119  mse = 14.514498  mae = 3.676454 time =  2025-02-18 10:55:16.081049\n",
      "Epoch: train 0034 loss = 0.540485  acc = 0.882130  r2 = 0.973297  mse = 1.578847  mae = 1.122984 time =  2025-02-18 10:58:04.114288\n",
      "Epoch: test 0034 loss = 0.081107  acc = 0.926351  r2 = 0.976884  mse = 0.296362  mae = 0.481264 time =  2025-02-18 10:58:04.114288\n",
      "Epoch: train 0035 loss = 1.018910  acc = 0.840178  r2 = 0.948614  mse = 3.038289  mae = 1.581157 time =  2025-02-18 11:00:52.327876\n",
      "Epoch: test 0035 loss = 0.149850  acc = 0.895828  r2 = 0.955604  mse = 0.569182  mae = 0.670590 time =  2025-02-18 11:00:52.327876\n",
      "Epoch: train 0036 loss = 1.884806  acc = 0.765316  r2 = 0.904170  mse = 5.666141  mae = 2.209575 time =  2025-02-18 11:03:40.606465\n",
      "Epoch: test 0036 loss = 0.298790  acc = 0.847072  r2 = 0.909624  mse = 1.158675  mae = 0.985493 time =  2025-02-18 11:03:40.606465\n",
      "Epoch: train 0037 loss = 1.421531  acc = 0.819025  r2 = 0.927603  mse = 4.280588  mae = 1.868105 time =  2025-02-18 11:06:29.170926\n",
      "Epoch: test 0037 loss = 0.216138  acc = 0.875462  r2 = 0.934452  mse = 0.840362  mae = 0.817319 time =  2025-02-18 11:06:29.170926\n",
      "Epoch: train 0038 loss = 2.751235  acc = 0.711482  r2 = 0.859584  mse = 8.302365  mae = 2.692160 time =  2025-02-18 11:09:18.005058\n",
      "Epoch: test 0038 loss = 0.460758  acc = 0.810438  r2 = 0.859653  mse = 1.799336  mae = 1.270770 time =  2025-02-18 11:09:18.005058\n",
      "Epoch: train 0039 loss = 0.917326  acc = 0.847416  r2 = 0.953841  mse = 2.729254  mae = 1.458798 time =  2025-02-18 11:12:06.214586\n",
      "Epoch: test 0039 loss = 0.133082  acc = 0.909468  r2 = 0.960805  mse = 0.502509  mae = 0.614202 time =  2025-02-18 11:12:06.214586\n",
      "Epoch: train 0040 loss = 2.817781  acc = 0.679343  r2 = 0.855963  mse = 8.516432  mae = 2.749161 time =  2025-02-18 11:14:54.485564\n",
      "Epoch: test 0040 loss = 0.454947  acc = 0.804422  r2 = 0.860866  mse = 1.783783  mae = 1.228236 time =  2025-02-18 11:14:54.485564\n",
      "Epoch: train 0041 loss = 42.824232  acc = 0.312980  r2 = -1.198929  mse = 130.015562  mae = 9.421077 time =  2025-02-18 11:17:42.816281\n",
      "Epoch: test 0041 loss = 11.385394  acc = 0.305565  r2 = -2.476287  mse = 44.568236  mae = 5.956067 time =  2025-02-18 11:17:42.816281\n",
      "Epoch: train 0042 loss = 0.541480  acc = 0.878384  r2 = 0.973284  mse = 1.579659  mae = 1.109324 time =  2025-02-18 11:20:31.237991\n",
      "Epoch: test 0042 loss = 0.088161  acc = 0.925062  r2 = 0.975343  mse = 0.316117  mae = 0.495496 time =  2025-02-18 11:20:31.237991\n",
      "Epoch: train 0043 loss = 1.686089  acc = 0.748848  r2 = 0.913755  mse = 5.099387  mae = 2.137809 time =  2025-02-18 11:23:19.963800\n",
      "Epoch: test 0043 loss = 0.289874  acc = 0.841260  r2 = 0.911619  mse = 1.133103  mae = 0.993360 time =  2025-02-18 11:23:19.963800\n",
      "Epoch: train 0044 loss = 0.362863  acc = 0.940515  r2 = 0.986540  mse = 0.795835  mae = 0.635376 time =  2025-02-18 11:26:08.587125\n",
      "Epoch: test 0044 loss = 0.083352  acc = 0.958713  r2 = 0.983802  mse = 0.207666  mae = 0.336833 time =  2025-02-18 11:26:08.587125\n",
      "Epoch: train 0045 loss = 0.447899  acc = 0.878517  r2 = 0.978812  mse = 1.252758  mae = 1.040330 time =  2025-02-18 11:28:56.603391\n",
      "Epoch: test 0045 loss = 0.084138  acc = 0.918543  r2 = 0.977619  mse = 0.286942  mae = 0.485382 time =  2025-02-18 11:28:56.603391\n",
      "Epoch: train 0046 loss = 0.369456  acc = 0.895729  r2 = 0.982320  mse = 1.045379  mae = 0.942843 time =  2025-02-18 11:31:45.915863\n",
      "Epoch: test 0046 loss = 0.065423  acc = 0.929562  r2 = 0.982351  mse = 0.226270  mae = 0.430713 time =  2025-02-18 11:31:45.915863\n",
      "Epoch: train 0047 loss = 0.289517  acc = 0.919003  r2 = 0.987081  mse = 0.763863  mae = 0.786786 time =  2025-02-18 11:34:34.234380\n",
      "Epoch: test 0047 loss = 0.052646  acc = 0.942912  r2 = 0.987283  mse = 0.163036  mae = 0.360972 time =  2025-02-18 11:34:34.234380\n",
      "Epoch: train 0048 loss = 0.301555  acc = 0.919812  r2 = 0.986234  mse = 0.813964  mae = 0.788488 time =  2025-02-18 11:37:23.481516\n",
      "Epoch: test 0048 loss = 0.053302  acc = 0.943816  r2 = 0.986630  mse = 0.171407  mae = 0.364181 time =  2025-02-18 11:37:23.481516\n",
      "Epoch: train 0049 loss = 0.506773  acc = 0.893593  r2 = 0.975770  mse = 1.432648  mae = 1.065175 time =  2025-02-18 11:40:12.372090\n",
      "Epoch: test 0049 loss = 0.078611  acc = 0.932949  r2 = 0.978984  mse = 0.269437  mae = 0.456399 time =  2025-02-18 11:40:12.372090\n",
      "Epoch: train 0050 loss = 2.222960  acc = 0.798073  r2 = 0.886290  mse = 6.723286  mae = 2.318334 time =  2025-02-18 11:43:01.002723\n",
      "Epoch: test 0050 loss = 0.424151  acc = 0.834392  r2 = 0.871044  mse = 1.653294  mae = 1.227394 time =  2025-02-18 11:43:01.002723\n",
      "Epoch: train 0051 loss = 0.420759  acc = 0.904991  r2 = 0.981731  mse = 1.080175  mae = 0.908038 time =  2025-02-18 11:45:51.387363\n",
      "Epoch: test 0051 loss = 0.069225  acc = 0.940652  r2 = 0.984298  mse = 0.201310  mae = 0.391392 time =  2025-02-18 11:45:51.387363\n",
      "Epoch: train 0052 loss = 0.401870  acc = 0.898184  r2 = 0.981524  mse = 1.092443  mae = 0.949888 time =  2025-02-18 11:48:39.945948\n",
      "Epoch: test 0052 loss = 0.068468  acc = 0.931017  r2 = 0.982380  mse = 0.225895  mae = 0.424898 time =  2025-02-18 11:48:39.945948\n",
      "Epoch: train 0053 loss = 0.739995  acc = 0.882597  r2 = 0.963203  mse = 2.175711  mae = 1.301478 time =  2025-02-18 11:51:28.939221\n",
      "Epoch: test 0053 loss = 0.120590  acc = 0.914008  r2 = 0.965099  mse = 0.447448  mae = 0.621559 time =  2025-02-18 11:51:28.939221\n",
      "Epoch: train 0054 loss = 0.515673  acc = 0.886846  r2 = 0.976313  mse = 1.400536  mae = 1.079064 time =  2025-02-18 11:54:18.212775\n",
      "Epoch: test 0054 loss = 0.081571  acc = 0.926363  r2 = 0.979469  mse = 0.263214  mae = 0.460078 time =  2025-02-18 11:54:18.212775\n",
      "Epoch: train 0055 loss = 1.517740  acc = 0.806853  r2 = 0.923153  mse = 4.543696  mae = 1.952249 time =  2025-02-18 11:57:06.778564\n",
      "Epoch: test 0055 loss = 0.288694  acc = 0.856211  r2 = 0.913605  mse = 1.107645  mae = 1.015333 time =  2025-02-18 11:57:06.778564\n",
      "Epoch: train 0056 loss = 22.677113  acc = 0.452580  r2 = -0.167750  mse = 69.045280  mae = 7.071270 time =  2025-02-18 11:59:54.702173\n",
      "Epoch: test 0056 loss = 5.877340  acc = 0.471536  r2 = -0.799662  mse = 23.072822  mae = 4.386485 time =  2025-02-18 11:59:54.702173\n",
      "Epoch: train 0057 loss = 0.081049  acc = 0.964684  r2 = 0.997927  mse = 0.122579  mae = 0.288676 time =  2025-02-18 12:02:43.019086\n",
      "Epoch: test 0057 loss = 0.026379  acc = 0.968319  r2 = 0.994866  mse = 0.065825  mae = 0.219206 time =  2025-02-18 12:02:43.019086\n",
      "Epoch: train 0058 loss = 0.154447  acc = 0.945534  r2 = 0.994965  mse = 0.297719  mae = 0.472588 time =  2025-02-18 12:05:31.489115\n",
      "Epoch: test 0058 loss = 0.032101  acc = 0.959725  r2 = 0.994378  mse = 0.072077  mae = 0.233443 time =  2025-02-18 12:05:31.489115\n",
      "Epoch: train 0059 loss = 26.869409  acc = 0.442354  r2 = -0.382576  mse = 81.747220  mae = 7.539360 time =  2025-02-18 12:08:19.747088\n",
      "Epoch: test 0059 loss = 7.210290  acc = 0.435538  r2 = -1.205512  mse = 28.276085  mae = 4.788957 time =  2025-02-18 12:08:19.747088\n",
      "Epoch: train 0060 loss = 0.096265  acc = 0.955561  r2 = 0.997988  mse = 0.118936  mae = 0.285155 time =  2025-02-18 12:11:07.976007\n",
      "Epoch: test 0060 loss = 0.026196  acc = 0.974095  r2 = 0.995924  mse = 0.052254  mae = 0.188554 time =  2025-02-18 12:11:07.976007\n",
      "Epoch: train 0061 loss = 0.636872  acc = 0.844052  r2 = 0.970193  mse = 1.762379  mae = 1.261610 time =  2025-02-18 12:13:56.503003\n",
      "Epoch: test 0061 loss = 0.115104  acc = 0.902829  r2 = 0.968558  mse = 0.403104  mae = 0.601695 time =  2025-02-18 12:13:56.503003\n",
      "Epoch: train 0062 loss = 0.236696  acc = 0.925195  r2 = 0.991062  mse = 0.528450  mae = 0.647895 time =  2025-02-18 12:16:44.820830\n",
      "Epoch: test 0062 loss = 0.041840  acc = 0.954242  r2 = 0.991845  mse = 0.104555  mae = 0.278192 time =  2025-02-18 12:16:44.820830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train 0063 loss = 8.651598  acc = 0.577984  r2 = 0.570418  mse = 25.399805  mae = 4.507401 time =  2025-02-18 12:19:33.976062\n",
      "Epoch: test 0063 loss = 2.072778  acc = 0.658821  r2 = 0.388023  mse = 7.845935  mae = 2.645356 time =  2025-02-18 12:19:33.976062\n",
      "Epoch: train 0064 loss = 0.504997  acc = 0.878407  r2 = 0.977828  mse = 1.310966  mae = 1.061397 time =  2025-02-18 12:22:22.792119\n",
      "Epoch: test 0064 loss = 0.096917  acc = 0.920182  r2 = 0.975429  mse = 0.315010  mae = 0.534255 time =  2025-02-18 12:22:22.792119\n",
      "Epoch: train 0065 loss = 0.296360  acc = 0.923236  r2 = 0.986920  mse = 0.773375  mae = 0.768173 time =  2025-02-18 12:25:11.400292\n",
      "Epoch: test 0065 loss = 0.051852  acc = 0.949545  r2 = 0.987138  mse = 0.164903  mae = 0.366901 time =  2025-02-18 12:25:11.400292\n",
      "Epoch: train 0066 loss = 0.338281  acc = 0.913321  r2 = 0.985125  mse = 0.879535  mae = 0.851254 time =  2025-02-18 12:27:59.590163\n",
      "Epoch: test 0066 loss = 0.056020  acc = 0.941627  r2 = 0.986502  mse = 0.173052  mae = 0.380798 time =  2025-02-18 12:27:59.590163\n",
      "Epoch: train 0067 loss = 0.548425  acc = 0.891663  r2 = 0.975104  mse = 1.472012  mae = 1.096786 time =  2025-02-18 12:30:48.354933\n",
      "Epoch: test 0067 loss = 0.092045  acc = 0.924307  r2 = 0.976503  mse = 0.301245  mae = 0.513562 time =  2025-02-18 12:30:48.354933\n",
      "Epoch: train 0068 loss = 7.779039  acc = 0.672986  r2 = 0.599701  mse = 23.668369  mae = 4.173185 time =  2025-02-18 12:33:36.737979\n",
      "Epoch: test 0068 loss = 2.006777  acc = 0.685160  r2 = 0.385726  mse = 7.875384  mae = 2.581932 time =  2025-02-18 12:33:36.737979\n",
      "Epoch: train 0069 loss = 0.111273  acc = 0.965555  r2 = 0.997062  mse = 0.173716  mae = 0.295527 time =  2025-02-18 12:36:24.932668\n",
      "Epoch: test 0069 loss = 0.022878  acc = 0.981862  r2 = 0.996770  mse = 0.041416  mae = 0.134875 time =  2025-02-18 12:36:24.932668\n",
      "Epoch: train 0070 loss = 0.715031  acc = 0.818451  r2 = 0.964997  mse = 2.069600  mae = 1.381618 time =  2025-02-18 12:39:13.648083\n",
      "Epoch: test 0070 loss = 0.139254  acc = 0.893972  r2 = 0.959595  mse = 0.518016  mae = 0.703086 time =  2025-02-18 12:39:13.648083\n",
      "Epoch: train 0071 loss = 0.336937  acc = 0.918516  r2 = 0.984940  mse = 0.890422  mae = 0.829916 time =  2025-02-18 12:42:01.545757\n",
      "Epoch: test 0071 loss = 0.052582  acc = 0.947432  r2 = 0.987007  mse = 0.166582  mae = 0.362421 time =  2025-02-18 12:42:01.545757\n",
      "Epoch: train 0072 loss = 48.835570  acc = 0.268037  r2 = -1.519425  mse = 148.965397  mae = 10.000120 time =  2025-02-18 12:44:49.978236\n",
      "Epoch: test 0072 loss = 12.994044  acc = 0.267247  r2 = -2.979092  mse = 51.014513  mae = 6.337660 time =  2025-02-18 12:44:49.978236\n",
      "Epoch: train 0073 loss = 0.168841  acc = 0.938923  r2 = 0.993944  mse = 0.358062  mae = 0.458212 time =  2025-02-18 12:47:38.060535\n",
      "Epoch: test 0073 loss = 0.038079  acc = 0.968873  r2 = 0.991913  mse = 0.103687  mae = 0.234759 time =  2025-02-18 12:47:38.060535\n",
      "Epoch: train 0074 loss = 0.185204  acc = 0.946576  r2 = 0.992218  mse = 0.460117  mae = 0.566029 time =  2025-02-18 12:50:26.138504\n",
      "Epoch: test 0074 loss = 0.034350  acc = 0.961735  r2 = 0.991835  mse = 0.104674  mae = 0.277746 time =  2025-02-18 12:50:26.138504\n",
      "Epoch: train 0075 loss = 0.390018  acc = 0.920418  r2 = 0.981071  mse = 1.119225  mae = 0.887091 time =  2025-02-18 12:53:14.432314\n",
      "Epoch: test 0075 loss = 0.072455  acc = 0.942815  r2 = 0.979330  mse = 0.265005  mae = 0.456708 time =  2025-02-18 12:53:14.432314\n",
      "Epoch: train 0076 loss = 0.763444  acc = 0.844186  r2 = 0.963249  mse = 2.172940  mae = 1.362549 time =  2025-02-18 12:56:02.821199\n",
      "Epoch: test 0076 loss = 0.135639  acc = 0.902842  r2 = 0.961731  mse = 0.490636  mae = 0.667929 time =  2025-02-18 12:56:02.821199\n",
      "Epoch: train 0077 loss = 31.955440  acc = 0.404061  r2 = -0.648109  mse = 97.447311  mae = 8.099236 time =  2025-02-18 12:58:51.361679\n",
      "Epoch: test 0077 loss = 8.664721  acc = 0.402584  r2 = -1.653245  mse = 34.016305  mae = 5.170813 time =  2025-02-18 12:58:51.361679\n",
      "Epoch: train 0078 loss = 0.130638  acc = 0.966387  r2 = 0.996045  mse = 0.233844  mae = 0.354226 time =  2025-02-18 13:01:39.531023\n",
      "Epoch: test 0078 loss = 0.027567  acc = 0.975120  r2 = 0.995370  mse = 0.059362  mae = 0.183896 time =  2025-02-18 13:01:39.531023\n",
      "Epoch: train 0079 loss = 0.393120  acc = 0.906230  r2 = 0.981765  mse = 1.078200  mae = 0.931786 time =  2025-02-18 13:04:27.737807\n",
      "Epoch: test 0079 loss = 0.075885  acc = 0.934013  r2 = 0.979481  mse = 0.263063  mae = 0.480989 time =  2025-02-18 13:04:27.737807\n",
      "Epoch: train 0080 loss = 0.282089  acc = 0.933790  r2 = 0.987007  mse = 0.768247  mae = 0.720048 time =  2025-02-18 13:07:16.603038\n",
      "Epoch: test 0080 loss = 0.050759  acc = 0.955000  r2 = 0.986634  mse = 0.171358  mae = 0.363246 time =  2025-02-18 13:07:16.603038\n",
      "Epoch: train 0081 loss = 0.330847  acc = 0.922452  r2 = 0.984547  mse = 0.913694  mae = 0.735862 time =  2025-02-18 13:10:05.278759\n",
      "Epoch: test 0081 loss = 0.065789  acc = 0.957590  r2 = 0.981973  mse = 0.231117  mae = 0.382390 time =  2025-02-18 13:10:05.278759\n",
      "Epoch: train 0082 loss = 0.389255  acc = 0.917001  r2 = 0.981722  mse = 1.080690  mae = 0.900721 time =  2025-02-18 13:12:54.273149\n",
      "Epoch: test 0082 loss = 0.070644  acc = 0.940274  r2 = 0.980714  mse = 0.247262  mae = 0.449819 time =  2025-02-18 13:12:54.273149\n",
      "Epoch: train 0083 loss = 0.356503  acc = 0.904506  r2 = 0.983664  mse = 0.965884  mae = 0.780168 time =  2025-02-18 13:15:43.263827\n",
      "Epoch: test 0083 loss = 0.059453  acc = 0.959925  r2 = 0.984533  mse = 0.198296  mae = 0.350269 time =  2025-02-18 13:15:43.263827\n",
      "Epoch: train 0084 loss = 0.800271  acc = 0.887707  r2 = 0.959945  mse = 2.368323  mae = 1.275035 time =  2025-02-18 13:18:31.883374\n",
      "Epoch: test 0084 loss = 0.164343  acc = 0.919433  r2 = 0.951208  mse = 0.625549  mae = 0.690851 time =  2025-02-18 13:18:31.883374\n",
      "Epoch: train 0085 loss = 1.127143  acc = 0.866657  r2 = 0.942900  mse = 3.376143  mae = 1.580294 time =  2025-02-18 13:21:19.956820\n",
      "Epoch: test 0085 loss = 0.220354  acc = 0.892924  r2 = 0.933659  mse = 0.850540  mae = 0.847472 time =  2025-02-18 13:21:19.956820\n",
      "Epoch: train 0086 loss = 1.136611  acc = 0.857993  r2 = 0.943892  mse = 3.317475  mae = 1.598484 time =  2025-02-18 13:24:08.456844\n",
      "Epoch: test 0086 loss = 0.210821  acc = 0.891188  r2 = 0.938538  mse = 0.787988  mae = 0.824575 time =  2025-02-18 13:24:08.456844\n",
      "Epoch: train 0087 loss = 2.520207  acc = 0.820088  r2 = 0.871449  mse = 7.600803  mae = 2.302346 time =  2025-02-18 13:26:57.978568\n",
      "Epoch: test 0087 loss = 0.624501  acc = 0.836721  r2 = 0.810453  mse = 2.430113  mae = 1.387680 time =  2025-02-18 13:26:57.978568\n",
      "Epoch: train 0088 loss = 1.359971  acc = 0.800446  r2 = 0.932183  mse = 4.009789  mae = 1.837084 time =  2025-02-18 13:29:46.903481\n",
      "Epoch: test 0088 loss = 0.278514  acc = 0.865863  r2 = 0.917428  mse = 1.058630  mae = 0.980733 time =  2025-02-18 13:29:46.903481\n",
      "Epoch: train 0089 loss = 0.464567  acc = 0.913565  r2 = 0.978311  mse = 1.282373  mae = 0.972527 time =  2025-02-18 13:32:35.211823\n",
      "Epoch: test 0089 loss = 0.083892  acc = 0.935819  r2 = 0.977409  mse = 0.289631  mae = 0.487886 time =  2025-02-18 13:32:35.211823\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "USE_MULTI_GPU = True\n",
    "# 设置默认的CUDA设备\n",
    "torch.cuda.set_device(0)\n",
    "# 初始化CUDA环境\n",
    "torch.cuda.init()\n",
    "if USE_MULTI_GPU and torch.cuda.device_count() > 1:\n",
    "    MULTI_GPU = True\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5\"  # 设置所有六张显卡的编号\n",
    "    device_ids = ['0','1','2','3','4','5',] # 设置所有六张显卡的编号\n",
    "else:\n",
    "    MULTI_GPU = False\n",
    "    device_ids = ['0']\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(MULTI_GPU)\n",
    "deviceCount = torch.cuda.device_count()\n",
    "torch.cuda.set_device(device)\n",
    "print(deviceCount)\n",
    "print(device)\n",
    "\n",
    "\n",
    "volve_train,volve_train_y_max,volve_train_y_min, volve_train_de_max,volve_train_de_min = data_load(bh_7_15)\n",
    "volve_test,volve_test_y_max,volve_test_y_min, volve_test_de_max,volve_test_de_min =  data_load(bh_2)\n",
    "\n",
    "model=TransAm().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()  # 占位符 索引为0.9\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=model_tf_lr, weight_decay=0.001)\n",
    "\n",
    "# # 定义学习率衰减策略\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.2)\n",
    "\n",
    "\n",
    "def train(TModel, loader,optimizer):\n",
    "    epoch_loss = 0\n",
    "    criterion = nn.MSELoss()  # 占位符 索引为0.9\n",
    "\n",
    "    for X, y in loader:\n",
    "        # X--[batch,seq,feature_size]  y--[batch,seq,feature_size]   64 300 13  64 50 13\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        mask = (torch.triu(torch.ones(y.size(1), y.size(1))) == 1).transpose(0, 1)\n",
    "        tgt_mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
    "\n",
    "        output = TModel(X, y, tgt_mask)\n",
    "        loss = criterion(output, y[:, :, -1])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(TModel.parameters(), 0.10)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "def test(TModel, tf_loader, y_max, y_min, de_max, de_min):\n",
    "    epoch_loss = 0\n",
    "    y_pre = []\n",
    "    y_true = []\n",
    "    y_depth = []\n",
    "    criterion = nn.MSELoss()  # 占位符 索引为0.9\n",
    "    for x, y in tf_loader:\n",
    "        with torch.no_grad():\n",
    "            label = y[:, :, -1].detach().view(1, len(y[:, :, -1]) * model_pre_len).squeeze()\n",
    "            label = label * (y_max - y_min) + y_min\n",
    "            label = label.numpy().tolist()\n",
    "            y_true += label\n",
    "\n",
    "            de = y[:, :, 0].detach().view(1, len(y[:, :, 0]) * model_pre_len).squeeze()\n",
    "            de = de * (de_max - de_min) + de_min\n",
    "            de = de.numpy().tolist()\n",
    "            y_depth += de\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            mask = (torch.triu(torch.ones(y.size(1), y.size(1))) == 1).transpose(0, 1)\n",
    "            tgt_mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
    "\n",
    "            output = TModel(x, y, tgt_mask)\n",
    "\n",
    "            loss = criterion(output, y[:, :, -1])\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            hat = output.cpu().detach().view(1, len(y[:, :, -1]) * model_pre_len).squeeze()\n",
    "            hat = hat * (y_max - y_min) + y_min\n",
    "            hat = hat.numpy().tolist()\n",
    "            y_pre += hat\n",
    "\n",
    "    label = np.array(y_true)\n",
    "    predict = np.array(y_pre)\n",
    "    dep = np.array(y_depth)\n",
    "\n",
    "    seq_label = label.reshape(int(len(label) / model_pre_len), model_pre_len)\n",
    "    seq_predict = predict.reshape(int(len(predict) / model_pre_len), model_pre_len)\n",
    "    seq_depth = dep.reshape(int(len(dep) / model_pre_len), model_pre_len)\n",
    "\n",
    "    true = np.concatenate((seq_label[:-1, 0], seq_label[-1, :]), axis=0)\n",
    "    depth = np.concatenate((seq_depth[:-1, 0], seq_depth[-1, :]), axis=0)\n",
    "    pre = averages(seq_predict)\n",
    "\n",
    "    r2 = r2_score(true, pre)\n",
    "    acc = 1 - (np.abs(pre - true) / (true + 1e-8)).mean()\n",
    "    mse = mean_squared_error(true, pre)\n",
    "\n",
    "    mae = mean_absolute_error(true, pre)\n",
    "\n",
    "    return acc, r2, mse, mae, epoch_loss, true, pre, depth\n",
    "\n",
    "def initiate():\n",
    "    train_acc_size = []\n",
    "    train_r2_size = []\n",
    "    train_mse_size = []\n",
    "    train_mae_size = []\n",
    "    train_loss_size = []\n",
    "\n",
    "    test_acc_size = []\n",
    "    test_r2_size = []\n",
    "    test_mse_size = []\n",
    "    test_mae_size = []\n",
    "    test_loss_size = []\n",
    "    total_acc = 0\n",
    "    for epoch in range(100):\n",
    "        start = datetime.now()\n",
    "        model.train()\n",
    "        train(model, volve_train,optimizer)\n",
    "        model.eval()\n",
    "        train_acc, train_r2, train_mse, train_mae, train_loss, true_train, pre_train, train_depth = test(model,\n",
    "                                                                                                         volve_train,\n",
    "                                                                                                         volve_train_y_max, volve_train_y_min,\n",
    "                                                                                                         volve_train_de_max, volve_train_de_min)\n",
    "        train_mse_size.append(train_mse)\n",
    "        train_mae_size.append(train_mae)\n",
    "        train_acc_size.append(train_acc)\n",
    "        train_r2_size.append(train_r2)\n",
    "        train_loss_size.append(train_loss)\n",
    "        print('Epoch:', 'train %04d' % epoch, 'loss =', '{:.6f}'.format(train_loss), ' acc =',\n",
    "              '{:.6f}'.format(train_acc), ' r2 =', '{:.6f}'.format(train_r2),\n",
    "              ' mse =', '{:.6f}'.format(train_mse), ' mae =', '{:.6f}'.format(train_mae), 'time = ', start)\n",
    "\n",
    "        test_acc, test_r2, test_mse, test_mae, test_loss, true_test, pre_test, test_depth = test(model, volve_test,\n",
    "                                                                                                 volve_test_y_max, volve_test_y_min,\n",
    "                                                                                                 volve_test_de_max, volve_test_de_min)\n",
    "        test_mse_size.append(test_mse)\n",
    "        test_mae_size.append(test_mae)\n",
    "        test_acc_size.append(test_acc)\n",
    "        test_r2_size.append(test_r2)\n",
    "        test_loss_size.append(test_loss)\n",
    "        print('Epoch:', 'test %04d' % epoch, 'loss =', '{:.6f}'.format(test_loss), ' acc =', '{:.6f}'.format(test_acc),\n",
    "              ' r2 =', '{:.6f}'.format(test_r2),\n",
    "              ' mse =', '{:.6f}'.format(test_mse), ' mae =', '{:.6f}'.format(test_mae), 'time = ', start)\n",
    "\n",
    "        loss_acc_mse_mae_dict = {'train_loss': train_loss_size, 'test_loss': test_loss_size,\n",
    "                                 'train_acc': train_acc_size, 'test_acc': test_acc_size,\n",
    "                                 'train_r2': train_r2_size, 'test_r2': test_r2_size,\n",
    "                                 'train_mse': train_mse_size, 'train_mae': train_mae_size,\n",
    "                                 'test_mse': test_mse_size, 'test_mae': test_mae_size, }\n",
    "        loss_acc_mse_mae = pd.DataFrame(loss_acc_mse_mae_dict)\n",
    "\n",
    "        train_de = pd.DataFrame(train_depth, columns=['train_depth'])\n",
    "        train_t = pd.DataFrame(true_train, columns=['train_true'])\n",
    "        train_p = pd.DataFrame(pre_train, columns=['train_pre'])\n",
    "        test_de = pd.DataFrame(test_depth, columns=['test_depth'])\n",
    "        test_t = pd.DataFrame(true_test, columns=['test_true'])\n",
    "        test_p = pd.DataFrame(pre_test, columns=['test_pre'])\n",
    "\n",
    "        csv_train = pd.concat([train_de, train_t, train_p], axis=1)\n",
    "        csv_test = pd.concat([test_de, test_t, test_p], axis=1)\n",
    "\n",
    "        loss_acc_mse_mae.to_csv('./compare/bh1/out/loss_acc_mse_mae_.csv', sep=\",\", index=True)\n",
    "\n",
    "        torch.save(model.state_dict(), './compare/bh1/model/Model_volve.pkl')\n",
    "\n",
    "        csv_train.to_csv('./compare/bh1/out/rel_pre_train.csv', sep=\",\", index=True)\n",
    "        csv_test.to_csv('./compare/bh1/out/rel_pre_test.csv', sep=\",\", index=True)\n",
    "\n",
    "        acc_loss_plot_two(loss_acc_mse_mae['train_loss'], loss_acc_mse_mae['test_loss'], 'loss',\n",
    "                      './compare/bh1/out/loss.png')\n",
    "        acc_loss_plot_two(loss_acc_mse_mae['train_r2'], loss_acc_mse_mae['test_r2'], 'r2',\n",
    "                      './compare/bh1/out/acc.png')\n",
    "        true_test_plot(csv_test['test_depth'], csv_test['test_true'], csv_test['test_pre'], 'test',\n",
    "                       './compare/bh1/out/pre_true_test.png')\n",
    "        true_test_plot(csv_train['train_depth'], csv_train['train_true'], csv_train['train_pre'], 'train',\n",
    "                        './compare/bh1/out/pre_true_train.png')\n",
    "\n",
    "\n",
    "initiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68af345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c2de0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02984b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6282c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198796c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ly3610",
   "language": "python",
   "name": "py3610"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
